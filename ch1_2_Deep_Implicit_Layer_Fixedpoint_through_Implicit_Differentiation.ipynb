{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn2A/sLXXbxpZmXMmRtNbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brahma2024/Deep-Implicit-Layers/blob/main/ch1_2_Deep_Implicit_Layer_Fixedpoint_through_Implicit_Differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving for Fixed Point Layer using Implicit Differentiation\n",
        "\n",
        "- Reference https://implicit-layers-tutorial.org/introduction/\n",
        "- section: **Differentiation in Implicit Layers**\n",
        "\n",
        "Note:\n",
        "- function g can be used to represent convolutions, self-attention, or any other feature\n",
        "\n",
        "# Key Points\n",
        "1. Solve for the root of the implicit layer g(x, z*) = 0, outisde of the automatic diferentiation tape\n",
        "2. Use the automatic differentiation tape to run the following assignment within the differentiation tape:\n",
        "    z:=zâ‹†âˆ’g(x,zâ‹†)\n",
        "  - this is like reinserting the partial dervatives âˆ’âˆ‚g/âˆ‚x to the autograd tape\n",
        "3. Add a backward hook to the backward pass that multiplies by (âˆ‚g/âˆ‚zâ‹†).transpose\n",
        "  - this will fix the backward pass so that it correctly implements the gradient according to the implicit function theorem"
      ],
      "metadata": {
        "id": "2gMEHcGfRrIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "fhGatyYVKWUs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qeH36zNIvQdT"
      },
      "outputs": [],
      "source": [
        "class TanhNewtonImplicitLayer(nn.Module):\n",
        "  def __init__(self, out_features, tol=1e-4, max_iter=1):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(out_features, out_features, bias=False) # (C, C)\n",
        "    self.tol = tol\n",
        "    self.max_iter = max_iter\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Run Newton's method outside of the autograd framework\n",
        "    with torch.no_grad():\n",
        "      z = torch.tanh(x) # (B, C) | Initial guess, z0 = tanh(x)\n",
        "      print(f'0. Start with :{z.shape=}')\n",
        "      self.iterations = 0\n",
        "      while self.iterations < self.max_iter: # by iteratively doing it cond: iterations < max_iter or (z - tanh(z_linear) < self.tol | objective is to find J = (âˆ‚g/âˆ‚zâ‹†)\n",
        "        z_linear = self.linear(z) + x # (B, C)\n",
        "        g = z - torch.tanh(z_linear) # (B, C)\n",
        "        self.err = torch.norm(g) # L2 norm | euclidean distance\n",
        "        if self.err < self.tol:\n",
        "          break\n",
        "\n",
        "        # newton Root Finding Method: 1. compute the gradient\n",
        "        # Jacobian = (âˆ‚g/âˆ‚zâ‹†), where\n",
        "        # g(x,z)= z âˆ’ tanh(Wz+x), hence\n",
        "        # J = I - diag(tanh'(Wz* + x)) * W, where\n",
        "        # Identity matrix = I\n",
        "        # Adjustment term = âˆ‚(tanh(Wz*+x))/âˆ‚z = diag(tanh'(Wz* + x)) * W\n",
        "        identity_matrix = torch.diag(torch.ones(g.shape[1]))         # (C, C) | square identity matriX\n",
        "        print(f'1 {identity_matrix.shape=}')\n",
        "        identity_matrix = identity_matrix.unsqueeze(0)               # (1, C, C) | add a batch dimension to I for broadcasting\n",
        "        print(f'2 {identity_matrix.shape=}')\n",
        "        adjustment_term_1 = (1/torch.cosh(z_linear)**2).unsqueeze(2) # (B, C, 1) | add 1 dim for channels\n",
        "        print(f'3 {adjustment_term_1.shape=}')\n",
        "        adjustment_term_2 = self.linear.weight.unsqueeze(0)          # (1, C, C) | add 1 dim for C\n",
        "        print(f'4 {adjustment_term_2.shape=}')\n",
        "        adjustment_term = adjustment_term_1 * adjustment_term_2      # (B, C, C)\n",
        "        print(f'5 {adjustment_term.shape=}')\n",
        "\n",
        "        J = identity_matrix - adjustment_term # (B, C, C) | (âˆ‚g/âˆ‚zâ‹†)\n",
        "        print(f'6 {J.shape=}')\n",
        "        # Newton Root finding method: 2. newton step update\n",
        "        # compute delta_z\n",
        "        delta_z = torch.linalg.solve(J, g.unsqueeze(2)) # (B, C, 1)\n",
        "        print(f'7 {delta_z.shape=}')\n",
        "        z = z - delta_z.squeeze(2) # (B, C) | z-new = z âˆ’ (âˆ‚g/âˆ‚zâ‹†)**âˆ’1 * g(z)\n",
        "        print(f'8 {z.shape=}')\n",
        "        print(f'{z[0]=} | {self.err=}')\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "    # renengage autograd and add the gradient hook\n",
        "    z = torch.tanh(self.linear(z) + x) # Recompute z to include it in the autograd computation graph\n",
        "    print(f'9 {z.shape=}')\n",
        "    # jacobian_transpose = J.transpose(1, 2)\n",
        "    # Solving the linear system ð½.ð‘‡ranspose * ð›¿ = grad, where ð½.ð‘‡ranspose is the transposed Jacobian and grad is the incoming gradient.\n",
        "    # call register_hook on a tensor, you are effectively saying,\n",
        "    # Whenever a gradient is computed for this tensor during backpropagation, apply this function to the gradient before proceeding.\n",
        "    # grad in register_hook is the gradient of the loss wrt to the tensor z\n",
        "    # It is computed during the backward pass.\n",
        "    # Specifically, it is the derivative of the loss function with respect to z, which is propagated from the loss through the layers of the network back to z.\n",
        "    z.register_hook(lambda grad: torch.linalg.solve(J.transpose(1, 2), g.unsqueeze(2)).squeeze(2))\n",
        "    print(f'10 {z.shape=} \\n')\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summing Up: Forward Pass\n",
        "- Objective: Find Jacobian matrix (âˆ‚g/âˆ‚zâ‹†)\n",
        "- Step 1: start with an initiat guess for z = tanh(x)\n",
        "- Next Steps to be executed iteratively\n",
        "  - Step 2:\n",
        "    - 'self.linear(z) + x': Applies a linear transformation to z and adds x.\n",
        "    - 'torch.tanh(...)': Applies the hyperbolic tangent activation function.\n",
        "  - Step 3: Calculate the jacobian matrix (gradient of function g(x, z*) wrt to\n",
        "   intermediate output z*\n",
        "   - J = I - tanh'(WZ* + X)\n",
        "   - Some Notes about the Jacobian calculation:\n",
        "    - g(z*, x) is of size (B, C), i.e. each batch sample is a vector of dimension/channels/features = C\n",
        "    - First we calculate the element-wise derivative of each element in each batch, i.e. the derivative of an element in a batch sample wrt to other elements will be zero\n",
        "    - this will result in a final jacobian of size (B, C, C) which will be block-diagonal\n",
        "    - The terms computed in order to compute the final jacobian matrix, include\n",
        "      - Identity matrix is of size (C, C)\n",
        "      - sehc(z)^2 = (1/cosh(z)^2) | this will be size (B, C) since we are calculating element-wise derivative\n",
        "      - next, multiple the sec^2 derivative term with the weights of the linear layer W which is of size (C, C)\n",
        "      - in order to broadcast derivative (sech^2) for each element to be multiplied with each respective element of linear layer weights, we do the following transformation\n",
        "      - sech^2 [:, :, None] | W [None, :, :] | i.e. add one spurious dimension to convert (B, C) -> (B, C, 1) | add one spurious dimension to convert (C, C) -> (1, C, C)\n",
        "      - resulting in a jacobian matrix of size (B, C, C) which stores the final gradients of each element in channel-dimention for each vector in batch (batch sample)\n",
        "\n",
        "\n",
        "# Summing up: Backward Pass\n",
        "- Once the gradients (Jacobian Matrix) = (âˆ‚g/âˆ‚zâ‹†) is computed\n",
        "- we recompute z = tanh(Wz + x) | creates the computational graph\n",
        "- register a grad hook to z which will propagate the gradients in the backward pass\n"
      ],
      "metadata": {
        "id": "p6P7UD0z82rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import gradcheck\n",
        "\n",
        "layer = TanhNewtonImplicitLayer(5, tol=1e-10).double()\n",
        "gradcheck(layer, torch.randn(3, 5, requires_grad=True, dtype=torch.double), check_undefined_grad=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JTBDFjpIKT66",
        "outputId": "e3292af1-6f9a-4f70-fee8-b2740522d3a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n",
            "0. Start with :z.shape=torch.Size([3, 5])\n",
            "1 identity_matrix.shape=torch.Size([5, 5])\n",
            "2 identity_matrix.shape=torch.Size([1, 5, 5])\n",
            "3 adjustment_term_1.shape=torch.Size([3, 5, 1])\n",
            "4 adjustment_term_2.shape=torch.Size([1, 5, 5])\n",
            "5 adjustment_term.shape=torch.Size([3, 5, 5])\n",
            "6 J.shape=torch.Size([3, 5, 5])\n",
            "7 delta_z.shape=torch.Size([3, 5, 1])\n",
            "8 z.shape=torch.Size([3, 5])\n",
            "z[0]=tensor([-0.3671, -0.8310, -0.5719,  0.3761,  0.8552], dtype=torch.float64) | self.err=tensor(0.8252, dtype=torch.float64)\n",
            "9 z.shape=torch.Size([3, 5])\n",
            "10 z.shape=torch.Size([3, 5])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GradcheckError",
          "evalue": "Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.7941, -0.0164,  0.2345, -0.2156, -0.0710,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0374,  0.2749, -0.0225, -0.0118,  0.0019,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.1351, -0.0235,  0.7250,  0.1227,  0.0316,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0341, -0.0669, -0.1918,  0.7841, -0.0254,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-0.0234,  0.0052, -0.0846,  0.0446,  0.2596,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8772, -0.1005,  0.2043,\n         -0.0248, -0.1908,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1089,  0.6978, -0.0557,\n         -0.0027,  0.0068,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1158, -0.0291,  0.6325,\n          0.0098,  0.0605,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0025, -0.0157, -0.0134,\n          0.0732, -0.0049,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0461,  0.0447, -0.1345,\n          0.0094,  0.5600,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.3809, -0.0236,  0.0075, -0.0516, -0.0384],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0478,  0.6334, -0.0049, -0.0017,  0.0102],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0046, -0.0027,  0.0553,  0.0042,  0.0026],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0106, -0.0678, -0.0060,  0.3374, -0.0060],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000, -0.0041,  0.0107, -0.0052,  0.0214,  0.2393]],\n       dtype=torch.float64)\nanalytical:tensor([[ 0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,\n          0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894],\n        [-0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241,\n         -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241],\n        [ 0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,\n          0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033],\n        [-0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979,\n         -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979],\n        [-0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309,\n         -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309],\n        [ 0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,\n          0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650],\n        [-0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562,\n         -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562],\n        [-0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876,\n         -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876],\n        [ 0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,\n          0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119],\n        [ 0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,\n          0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151],\n        [ 0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,\n          0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602],\n        [-0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707,\n         -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707],\n        [ 0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,\n          0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025],\n        [ 0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,\n          0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045],\n        [-0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081,\n         -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081]],\n       dtype=torch.float64)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGradcheckError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-28095a63542c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTanhNewtonImplicitLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_undefined_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gradcheck_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2076\u001b[0m         \u001b[0m_fast_gradcheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_slow_gradcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m     )\n\u001b[0;32m-> 2078\u001b[0;31m     _gradcheck_real_imag(\n\u001b[0m\u001b[1;32m   2079\u001b[0m         \u001b[0mgradcheck_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1486\u001b[0m             )\n\u001b[1;32m   1487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m             gradcheck_fn(\n\u001b[0m\u001b[1;32m   1489\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m                 \u001b[0mfunc_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_allclose_with_type_promotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                     raise GradcheckError(\n\u001b[0m\u001b[1;32m   1630\u001b[0m                         \u001b[0m_get_notallclose_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m                     )\n",
            "\u001b[0;31mGradcheckError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.7941, -0.0164,  0.2345, -0.2156, -0.0710,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0374,  0.2749, -0.0225, -0.0118,  0.0019,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.1351, -0.0235,  0.7250,  0.1227,  0.0316,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0341, -0.0669, -0.1918,  0.7841, -0.0254,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-0.0234,  0.0052, -0.0846,  0.0446,  0.2596,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8772, -0.1005,  0.2043,\n         -0.0248, -0.1908,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1089,  0.6978, -0.0557,\n         -0.0027,  0.0068,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1158, -0.0291,  0.6325,\n          0.0098,  0.0605,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0025, -0.0157, -0.0134,\n          0.0732, -0.0049,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0461,  0.0447, -0.1345,\n          0.0094,  0.5600,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.3809, -0.0236,  0.0075, -0.0516, -0.0384],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0478,  0.6334, -0.0049, -0.0017,  0.0102],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0046, -0.0027,  0.0553,  0.0042,  0.0026],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0106, -0.0678, -0.0060,  0.3374, -0.0060],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000, -0.0041,  0.0107, -0.0052,  0.0214,  0.2393]],\n       dtype=torch.float64)\nanalytical:tensor([[ 0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,\n          0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894,  0.2894],\n        [-0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241,\n         -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241, -0.0241],\n        [ 0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,\n          0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033,  0.2033],\n        [-0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979,\n         -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979, -0.1979],\n        [-0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309,\n         -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309, -0.0309],\n        [ 0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,\n          0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650,  0.2650],\n        [-0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562,\n         -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562, -0.1562],\n        [-0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876,\n         -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876, -0.0876],\n        [ 0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,\n          0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119],\n        [ 0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,\n          0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151,  0.1151],\n        [ 0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,\n          0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602,  0.0602],\n        [-0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707,\n         -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707, -0.2707],\n        [ 0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,\n          0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025],\n        [ 0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,\n          0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045,  0.0045],\n        [-0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081,\n         -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081]],\n       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.randn(10, 50)\n",
        "im1 = torch.diag(torch.ones(g.shape[1]))\n",
        "im1 = im1.unsqueeze(0)\n",
        "td1 = 1/(torch.cosh(g)**2)\n",
        "td1 = td1.unsqueeze(2)\n",
        "im2 = torch.eye(g.shape[1])[None, :, :]\n",
        "td2 = (1/(torch.cosh(g)**2))[:, :, None]\n",
        "im1.shape, im2.shape, torch.allclose(im1, im2), td1.shape, td2.shape, torch.allclose(td1, td2)\n",
        "\n",
        "j1 = im1 - td1\n",
        "j1.shape, g.shape\n",
        "\n",
        "delta_z = torch.linalg.solve(j1, g.unsqueeze(2))\n",
        "delta_z.shape"
      ],
      "metadata": {
        "id": "aS_kv1FKKQps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}